{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- The Lucas-Kanade is  x  and does  y  by method  z\n",
    "\n",
    "\n",
    "The Horn-Schunk is  x  and does  y  by method  z\n",
    "The Average Angular Error (AAE) is  x  and does  y  by method  z\n",
    "The End-Point Error (EPE) is  x  and does  y  by method  z\n",
    "The colored maps are  x  and reveal/translate  y -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- To calculate the Optical Flow (OF) provenient from the Horn-Schunk (HS) method -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Optical Flow (OF) Calculation:\n",
    "- Multichannel Lucas-Kanade (LK)\n",
    "Is a local techniquee and assumes the surrounding pixels belong to the same surface, moving as one\n",
    "\n",
    "\n",
    "\n",
    "- Mutichannel Horn-Schunk (HS)\\\n",
    "  - Is a global method very sensitive to noise that propagates the neighbourhood information across large regions with the same intensity\n",
    "  - The colored version can be minimized by the Euler-Lagrange eqs. with Neuman boundaries -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Due to the short span available to embrace the project, some results are not as sactisfactory as they could, this when comparing them with the ones presented in the paper \"Revisiting Lucas-Kanade and Horn-Schunck\"\n",
    "This project  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following project elaborates on Lucas-Kanade (LK) and Horn-Schunk (HS), two optical flow (OF) techniques, respectively Local and Global. These methods were fitted with multi-channel, multi-resolution, iterative refinement features to upgrade their capabilities.\\\n",
    "LK is a local technique and assumes the surrounding pixels belong to the same surface (constant flow on the neighbourhood), moving as one. Also is relatively robust to image noise. \n",
    "Since it \"works with a neighbourhood basis\", this method can only be used when the distance between frames is small enough for its equation to hold, implying the warping methods used later.\n",
    "Another improvement to this function is the use of Shi-Tomasi corner detection algorithm, speeding the process by looking directly for the positions representative of the best match of Tomasi method, which are far fewer potential matches\n",
    "<!-- formulas? -->\n",
    "\n",
    "HS is a global method that yields a high density of flow vectors. As a consequence, it is very sensitive to noise that propagates the neighbourhood information across large regions with the same intensity. (assumes smoothness in flow over the whole image and tries to minimize distortions in flow)\n",
    "The colored version can be minimized by the Euler-Lagrange eqs. with Neuman boundaries\n",
    "This method also uses a Laplace smooth regularization\n",
    "\n",
    "<!-- formulas? -->\n",
    "\n",
    "These methods were upgraded with the multichannel (colors) components as well as the piramidal multiresolution.\\\n",
    "The dataset used contains images at a time zero and the next frame, time one.\n",
    "\n",
    "The piramidal (Coarse to fine Estimation) scheme is the following\\\n",
    "The calculation of the OF starts by applying a low pass gaussian filter to the images and a liner interpolation downscaling technique, three times, interchangeablly. <!-- This process reduces the flow calculation effort considerably  -->\\\n",
    "Next, the optical flow is calculated, using both HS and LK independently, resulting in two flow vectors for each iteration, in which is applied a median filter to uniformize the those vectors, then used to create a bicubic interpolated warped image.\\\n",
    "\n",
    "We need to use the optical flow to propagate from the lowest resolution to the highest resolution in order to find an accurate estimate of the optical flow. We start this off by calculating the optical flow at the lowest resolution, i.e at the top of the pyramid (Multi Resolution). We then upsample the calculated optical flow and use it to wrap the image of I0 on the second level of the pyramid towards I1 (larger resolution). Furthermore, we need the optical flow of current iterations to be propagated to the next iteration and thats why we defined a function which calculates the optical flow in a iterative fashion. It uses the optical flow from the previous iteration to wrap I0 towards I1. It then calculates the optical flow between the \"wraped\" image and the next image in order to refine the estimation of the optical flow. (Iterative Resolution)\n",
    "\n",
    "<!-- The same process is repeated one more time until the original image resolution is reached.\\ -->\n",
    "At that point, the OF calculated is summed with the OF of the warped image, obtaining the final optical flow\n",
    "The final OF vectors represent the movement occurred between the images (or frames). For as easier representation, these vectors were \"color coded\", with the attributed colors representing the magnitude and the orientation of the movement (flow).\n",
    "\n",
    "2\\\n",
    "https://www.frontiersin.org/articles/10.3389/fnins.2016.00176/full\\\n",
    "End Point Error (EPE) is calculated by comparing the estimated optical flow vector with a groundtruth OF vector, as it is defined by the module of the difference between them.\\\n",
    "The EPE calculated in this project is the Estimated OF, as the Groundtruth must be annotated to the source (if it is a video).\n",
    "\n",
    "Since EPE does not distinguish between angular deviation and speed difference, Average Angular Error (AAE) is calculated between the angular difference <!-- velocity vectors--> in the image plane. \n",
    "<!-- formulas? -->\n",
    "\n",
    "3\n",
    "<!-- insert table here -->\n",
    "The presented results deviate from the \"motivation\" paper. This may be attributed to the short duration of the project, although, there were achieved some good results representative of the flows occured.\n",
    "The means of comparison were the AAE and EPE, along with their standard deviations. Applied to the same image sequences as the paper.\n",
    "Resulting data from the paper concludes the superiority of the LK method, with both AAE and EPE values being lower.\n",
    "The same was confirmed by the current project \n",
    "\n",
    "<!-- bla bla bla -->\n",
    "\n",
    "In the direct comparison of the LK method with Multi-color, Multi-resolution and Iterative Refinement processing, the values obtained provide a better result (by almost an order of magnitude) if analyzing the AAE, unexpectadly, the EPE values are higher than the paper's. \n",
    "The differenciation in values might be due to some inaccuracy in OF vector gathering.\n",
    "These observations are proved true in all scenarios.\n",
    "\n",
    "4\n",
    "As the last task, it was calculated the optical flow in two videos/(image sequences), making a video of the representation of the flow using the same color coding and color space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "5109d816b82be14675a6b11f8e0f0d2e80f029176ed3710d54e125caa8520dfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
